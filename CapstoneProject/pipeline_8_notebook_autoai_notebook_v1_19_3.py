# -*- coding: utf-8 -*-
"""Pipeline 8 Notebook - AutoAI Notebook v1.19.3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mJutprCfNhQ0U_y4JKew83ZaMH0RqsEO
"""

!pip install ibm-watson-machine-learning | tail -n 1
!pip install autoai-libs==1.14.13 | tail -n 1
!pip install scikit-learn==1.1.1 | tail -n 1
!pip install xgboost==1.6.2 | tail -n 1

from ibm_watson_machine_learning.helpers import DataConnection
from ibm_watson_machine_learning.helpers import ContainerLocation

training_data_references = [
    DataConnection(
        data_asset_id='9c55fa88-1fad-4fe5-b207-17dc9607b7e7'
    ),
]
training_result_reference = DataConnection(
    location=ContainerLocation(
        path='auto_ml/d3fef484-a09b-42e9-9881-2b69f5f0178f/wml_data/c375c86d-aacf-4d7c-a161-ac337254e0c9/data/automl',
        model_location='auto_ml/d3fef484-a09b-42e9-9881-2b69f5f0178f/wml_data/c375c86d-aacf-4d7c-a161-ac337254e0c9/data/automl/model.zip',
        training_status='auto_ml/d3fef484-a09b-42e9-9881-2b69f5f0178f/wml_data/c375c86d-aacf-4d7c-a161-ac337254e0c9/training-status.json'
    )
)

experiment_metadata = dict(
    prediction_type='regression',
    prediction_column='indeks_pencemaran',
    holdout_size=0.1,
    scoring='neg_root_mean_squared_error',
    csv_separator=',',
    random_state=33,
    max_number_of_estimators=3,
    training_data_references=training_data_references,
    training_result_reference=training_result_reference,
    include_only_estimators=['RandomForestRegressorEstimator', 'DecisionTreeRegressorEstimator', 'RidgeEstimator', 'ExtraTreesRegressorEstimator', 'LinearRegressionEstimator', 'XGBRegressorEstimator', 'LGBMRegressorEstimator', 'SnapDecisionTreeRegressorEstimator', 'SnapRandomForestRegressorEstimator', 'SnapBoostingMachineRegressorEstimator', 'GradientBoostingRegressorEstimator'],
    deployment_url='https://us-south.ml.cloud.ibm.com',
    project_id='1245ea59-5da0-40f0-bfeb-d5022c8b9545',
    drop_duplicates=True,
    include_batched_ensemble_estimators=[]
)

import os, ast
CPU_NUMBER = 2
if 'RUNTIME_HARDWARE_SPEC' in os.environ:
    CPU_NUMBER = int(ast.literal_eval(os.environ['RUNTIME_HARDWARE_SPEC'])['num_cpu'])

api_key = 'PUT_YOUR_APIKEY_HERE'

wml_credentials = {
    "apikey": api_key,
    "url": experiment_metadata['deployment_url']
}

from ibm_watson_machine_learning import APIClient

wml_client = APIClient(wml_credentials)

if 'space_id' in experiment_metadata:
    wml_client.set.default_space(experiment_metadata['space_id'])
else:
    wml_client.set.default_project(experiment_metadata['project_id'])

training_data_references[0].set_client(wml_client)

train_X, test_X, train_y, test_y = training_data_references[0].read(experiment_metadata=experiment_metadata, with_holdout_split=True, use_flight=False)

from autoai_libs.transformers.exportable import ColumnSelector
from autoai_libs.transformers.exportable import NumpyColumnSelector
from autoai_libs.transformers.exportable import CompressStrings
from autoai_libs.transformers.exportable import NumpyReplaceMissingValues
from autoai_libs.transformers.exportable import NumpyReplaceUnknownValues
from autoai_libs.transformers.exportable import boolean2float
from autoai_libs.transformers.exportable import CatImputer
from autoai_libs.transformers.exportable import CatEncoder
import numpy as np
from autoai_libs.transformers.exportable import float32_transform
from autoai_libs.cognito.transforms.transform_utils import TAM
from sklearn.decomposition import PCA
from autoai_libs.cognito.transforms.transform_utils import FS1
from autoai_libs.cognito.transforms.transform_utils import TA1
import autoai_libs.utils.fc_methods
from xgboost import XGBRegressor
from sklearn.pipeline import make_pipeline

column_selector = ColumnSelector(columns_indices_list=[1, 2, 3, 4])
numpy_column_selector = NumpyColumnSelector(columns=[0, 1, 2, 3])
compress_strings = CompressStrings(
    compress_type="hash",
    dtypes_list=["char_str", "char_str", "char_str", "char_str"],
    missing_values_reference_list=["", "-", "?", float("nan")],
    misslist_list=[[], [], [], []],
)
numpy_replace_missing_values = NumpyReplaceMissingValues(
    missing_values=[], filling_values=float("nan")
)
numpy_replace_unknown_values = NumpyReplaceUnknownValues(
    filling_values=float("nan"),
    filling_values_list=[
        float("nan"), float("nan"), float("nan"), float("nan"),
    ],
    missing_values_reference_list=["", "-", "?", float("nan")],
)
cat_imputer = CatImputer(
    missing_values=float("nan"),
    sklearn_version_family="1",
    strategy="most_frequent",
)
cat_encoder = CatEncoder(
    encoding="ordinal",
    categories="auto",
    dtype=np.float64,
    handle_unknown="error",
    sklearn_version_family="1",
)
tam = TAM(
    tans_class=PCA(),
    name="pca",
    col_names=["nama_lokasi", "parameter", "satuan", "nilai"],
    col_dtypes=[
        np.dtype("float32"), np.dtype("float32"), np.dtype("float32"),
        np.dtype("float32"),
    ],
)
fs1_0 = FS1(
    cols_ids_must_keep=range(0, 4),
    additional_col_count_to_keep=4,
    ptype="regression",
)
ta1 = TA1(
    fun=np.rint,
    name="round",
    datatypes=["numeric"],
    feat_constraints=[autoai_libs.utils.fc_methods.is_not_categorical],
    col_names=[
        "nama_lokasi", "parameter", "satuan", "nilai", "pca_0", "pca_1",
        "pca_2", "pca_3",
    ],
    col_dtypes=[
        np.dtype("float32"), np.dtype("float32"), np.dtype("float32"),
        np.dtype("float32"), np.dtype("float32"), np.dtype("float32"),
        np.dtype("float32"), np.dtype("float32"),
    ],
)
fs1_1 = FS1(
    cols_ids_must_keep=range(0, 4),
    additional_col_count_to_keep=4,
    ptype="regression",
)
xgb_regressor = XGBRegressor(
    base_score=0.5,
    booster="gbtree",
    colsample_bylevel=1,
    colsample_bynode=1,
    colsample_bytree=1,
    gamma=0,
    gpu_id=-1,
    grow_policy="depthwise",
    interaction_constraints="",
    learning_rate=1.0,
    max_bin=256,
    max_cat_to_onehot=4,
    max_delta_step=0,
    max_depth=6,
    max_leaves=0,
    min_child_weight=5,
    missing=float("nan"),
    monotone_constraints="()",
    n_estimators=597,
    n_jobs=CPU_NUMBER,
    num_parallel_tree=1,
    predictor="auto",
    random_state=33,
    reg_alpha=0,
    reg_lambda=0.46477912375727587,
    sampling_method="uniform",
    scale_pos_weight=1,
    subsample=0.9134498114499188,
    tree_method="exact",
    validate_parameters=1,
    verbosity=0,
    silent=False,
    nthread=2,
    seed=33,
)

pipeline = make_pipeline(
    column_selector,
    numpy_column_selector,
    compress_strings,
    numpy_replace_missing_values,
    numpy_replace_unknown_values,
    boolean2float(),
    cat_imputer,
    cat_encoder,
    float32_transform(),
    tam,
    fs1_0,
    ta1,
    fs1_1,
    xgb_regressor,
)

from sklearn.metrics import make_scorer

from autoai_libs.scorers.scorers import neg_root_mean_squared_error

scorer = make_scorer(neg_root_mean_squared_error)

pipeline.fit(train_X.values, train_y.values.ravel());

score = scorer(pipeline, test_X.values, test_y.values)
print(score)

pipeline.predict(test_X.values[:5])

model_metadata = {
    wml_client.repository.ModelMetaNames.NAME: 'Trained AutoAI pipeline'
}

stored_model_details = wml_client.repository.store_model(model=pipeline, meta_props=model_metadata, experiment_metadata=experiment_metadata)

stored_model_details